{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# basic packages used throughout\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn packages for All-NBA models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_players = pd.read_csv('full_nba_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create All-NBA models from 1979-2009 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['g', 'mp', 'pts', 'trb', 'ast', 'vorp', 'ws']\n",
    "output = ['all-nba']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df_all_players[df_all_players['season_start'] < 2009]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_subset, test_size = 0.25)\n",
    "\n",
    "xtrain = train[features]\n",
    "ytrain = train[output]\n",
    "\n",
    "xtest = test[features]\n",
    "ytest = test[output]\n",
    "\n",
    "print(\"Training set size: %.0f\" % len(xtrain))\n",
    "print(\"Testing set size: %.0f\" % len(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(train['all-nba']), sum(test['all-nba']))\n",
    "print(sum(train['all-nba']) / len(xtrain), sum(test['all-nba']) / len(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits = 3, random_state = 0)\n",
    "\n",
    "def grid_search(model, grid):\n",
    "    clf = GridSearchCV(model, grid, cv = cv, n_jobs = -1, verbose = 2, iid = False, scoring = 'recall')\n",
    "    scores(clf)\n",
    "    \n",
    "    print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(model):\n",
    "    \n",
    "    model.fit(xtrain, ytrain.values.ravel())\n",
    "    y_pred = model.predict(xtest)\n",
    "    \n",
    "    print(\"Accuracy score: %.3f\" % metrics.accuracy_score(ytest, y_pred))\n",
    "    print(\"Recall: %.3f\" % metrics.recall_score(ytest, y_pred))\n",
    "    print(\"Precision: %.3f\" % metrics.precision_score(ytest, y_pred))\n",
    "    print(\"F1: %.3f\" % metrics.f1_score(ytest, y_pred))\n",
    "    \n",
    "    proba = model.predict_proba(xtest)\n",
    "    print(\"Log loss: %.3f\" % metrics.log_loss(ytest, proba))\n",
    "\n",
    "    pos_prob = proba[:, 1]\n",
    "    print(\"Area under ROC curve: %.3f\" % metrics.roc_auc_score(ytest, pos_prob))\n",
    "    \n",
    "    cv = cross_val_score(model, xtest, ytest.values.ravel(), cv = 3, scoring = 'accuracy')\n",
    "    print(\"Accuracy (cross validation score): %0.3f (+/- %0.3f)\" % (cv.mean(), cv.std() * 2))\n",
    "    \n",
    "    cv = cross_val_score(model, xtest, ytest.values.ravel(), cv = 3, scoring = 'recall')\n",
    "    print(\"Recall (cross validation score): %0.3f (+/- %0.3f)\" % (cv.mean(), cv.std() * 2))\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(probability = True, gamma = 'auto')\n",
    "\n",
    "y_svc = scores(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = [x for x in np.logspace(-4, 0, num = 5)]\n",
    "C = [x for x in np.logspace(-1, 3, num = 5)]\n",
    "probability = [True]\n",
    "\n",
    "grid = {'gamma': gamma,\n",
    "        'C': C,\n",
    "        'probability': probability}\n",
    "\n",
    "grid_search(svc, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel = 'rbf', gamma = 0.01, C = 10, probability = True)\n",
    "\n",
    "y_svc = scores(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 100, random_state = 0)\n",
    "\n",
    "y_rf = scores(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "n_estimators = [int(x) for x in np.linspace(start = 25, stop = 250, num = 10)]\n",
    "random_state = [0]\n",
    "\n",
    "grid = {'max_depth': max_depth,\n",
    "        'max_features': max_features,\n",
    "        'n_estimators': n_estimators,\n",
    "        'random_state': random_state}\n",
    "\n",
    "grid_search(rf, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth = 20, max_features = 'auto', n_estimators = 175, random_state = 0)\n",
    "\n",
    "y_rf = scores(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier()\n",
    "\n",
    "y_knn = scores(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = [x for x in np.arange(5, 21)]\n",
    "weights = ['uniform', 'distance']\n",
    "\n",
    "grid = {'n_neighbors': n_neighbors,\n",
    "        'weights': weights}\n",
    "\n",
    "grid_search(knn, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors = 5, weights = 'distance')\n",
    "\n",
    "y_knn = scores(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(random_state = 0)\n",
    "\n",
    "y_gbc = scores(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ['deviance']\n",
    "max_depth = [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "n_estimators = [int(x) for x in np.linspace(start = 25, stop = 250, num = 10)]\n",
    "random_state = [0]\n",
    "\n",
    "grid = {'loss': loss,\n",
    "        'max_depth': max_depth,\n",
    "        'max_features': max_features,\n",
    "        'n_estimators': n_estimators,\n",
    "        'random_state': random_state}\n",
    "\n",
    "grid_search(gbc, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(random_state = 0)\n",
    "\n",
    "y_gbc = scores(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyClassifier(strategy= \"stratified\", random_state = 0)\n",
    "\n",
    "y_dummy = scores(dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_pred, model_name):\n",
    "    cm = metrics.confusion_matrix(ytest, y_pred)\n",
    "\n",
    "    plt.style.use(\"fivethirtyeight\")\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    sns.heatmap(cm, annot=True, ax = ax, linewidth = 2, fmt='g')\n",
    "\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "\n",
    "    fig.suptitle(\"%s Confusion Matrix\" % model_name.upper(), weight = 'bold', size = 18, x = .45)\n",
    "    \n",
    "    fig.text(x = -0.02, y = -0.08,\n",
    "        s = '__________________________________________________________',\n",
    "        fontsize = 14, color = 'grey', horizontalalignment='left')\n",
    "\n",
    "    fig.text(x = -0.02, y = -.14,\n",
    "        s = 'https://dribbleanalytics.blog                     ',\n",
    "        fontsize = 14, fontname = 'Rockwell', color = 'grey', horizontalalignment='left')\n",
    "\n",
    "    fig.savefig('%s_cm.png' % model_name, dpi = 400, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_svc, 'svc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_rf, 'rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_knn, 'knn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_gbc, 'gbc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve(model):\n",
    "\n",
    "    proba = model.predict_proba(xtest)\n",
    "    pos_prob = proba[:, 1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(ytest, pos_prob)\n",
    "    \n",
    "    return (fpr, tpr, pos_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "roc, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, sharey = True, sharex = True)\n",
    "\n",
    "fpr, tpr, pos_prob = roc_curve(svc)\n",
    "ax1.plot(fpr, tpr)\n",
    "ax1.plot([0, 1], [0, 1], linestyle = '--')\n",
    "ax1.set_title(\"SVC: %.2f\" % metrics.roc_auc_score(ytest, pos_prob), size = 15, x = .485, ha = 'center')\n",
    "\n",
    "fpr, tpr, pos_prob = roc_curve(rf)\n",
    "ax2.plot(fpr, tpr)\n",
    "ax2.plot([0, 1], [0, 1], linestyle = '--')\n",
    "ax2.set_title(\"RF: %.2f\" % metrics.roc_auc_score(ytest, pos_prob), size = 15, x = .485, ha = 'center')\n",
    "\n",
    "fpr, tpr, pos_prob = roc_curve(knn)\n",
    "ax3.plot(fpr, tpr)\n",
    "ax3.plot([0, 1], [0, 1], linestyle = '--')\n",
    "ax3.set_title(\"KNN: %.2f\" % metrics.roc_auc_score(ytest, pos_prob), size = 15, x = .485, ha = 'center')\n",
    "\n",
    "fpr, tpr, pos_prob = roc_curve(gbc)\n",
    "ax4.plot(fpr, tpr)\n",
    "ax4.plot([0, 1], [0, 1], linestyle = '--')\n",
    "ax4.set_title(\"GBC: %.2f\" % metrics.roc_auc_score(ytest, pos_prob), size = 15, x = .485, ha = 'center')\n",
    "\n",
    "roc.text(-0.03, 0.5, \"True positive rate\", va='center', rotation='vertical', size = 18)\n",
    "roc.text(0.5, -0.045, \"False positive rate\", ha = 'center', size = 18)\n",
    "\n",
    "roc.suptitle(\"Model ROC Curves\", y = 1.045, weight = 'bold', size = 18)\n",
    "\n",
    "roc.text(x = -0.03, y = -0.08,\n",
    "        s = '______________________________________________________________',\n",
    "        fontsize = 14, color = 'grey', horizontalalignment='left')\n",
    "\n",
    "roc.text(x = -0.03, y = -.14,\n",
    "    s = 'https://dribbleanalytics.blog                     ',\n",
    "    fontsize = 14, fontname = 'Rockwell', color = 'grey', horizontalalignment='left')\n",
    "\n",
    "roc.savefig('roc.png', dpi = 400, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict All-NBA score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred(model_list, df_pred):\n",
    "    prob_list = []\n",
    "    for i in model_list:\n",
    "        proba = i.predict_proba(df_pred)\n",
    "        pos_prob = proba[:, 1]\n",
    "        prob_list.append(pos_prob)\n",
    "        \n",
    "    return prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df_all_players[df_all_players['season_start'] >= 2009].reset_index(drop = True)\n",
    "\n",
    "prob_list = make_pred([svc, rf, knn, gbc], df_pred[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vals = pd.DataFrame(data = np.transpose(prob_list), columns = ['svc', 'rf', 'knn', 'gbc'])\n",
    "pred_vals['avg'] = (pred_vals['svc'] + pred_vals['rf'] + pred_vals['knn'] + pred_vals['gbc']) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = df_pred[['player', 'season_start']], columns =\n",
    "                       ['player', 'season_start'])\n",
    "\n",
    "df[['svc', 'rf', 'knn', 'gbc']] = pred_vals[['svc', 'rf', 'knn', 'gbc']]\n",
    "df['avg'] = pred_vals['avg']\n",
    "\n",
    "df.to_csv('all-nba-predictions.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum = df[['player', 'season_start']].copy()\n",
    "\n",
    "df_sum[['svc', 'rf', 'knn', 'gbc', 'avg']] = df.groupby(\n",
    "    by = ['player'])['svc', 'rf', 'knn', 'gbc', 'avg'].transform(pd.Series.cumsum)\n",
    "\n",
    "df_sum.to_csv('all-nba-cumulative.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All-decade teams by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all-nba-predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_nba = df.groupby(by = ['player'])['svc'].sum()\n",
    "rf_nba = df.groupby(by = ['player'])['rf'].sum()\n",
    "knn_nba = df.groupby(by = ['player'])['knn'].sum()\n",
    "gbc_nba = df.groupby(by = ['player'])['gbc'].sum()\n",
    "\n",
    "tot_nba = df.groupby(by = ['player'])['avg'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_nba.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_nba.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_nba.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_nba.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_nba.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best player seasons in the decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_nba = df.groupby(by = ['player', 'season_start'])['avg'].max()\n",
    "\n",
    "max_nba.sort_values(ascending = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
